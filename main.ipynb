{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Necessary Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# File manipulation tools\n",
    "import os\n",
    "import pandas as pd\n",
    "import tarfile\n",
    "import urllib.request\n",
    "\n",
    "# Data visualization tools\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Preprocessing tools\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder, StandardScaler\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "# Predictors\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "from sklearn.linear_model import LogisticRegression, SGDClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, VotingClassifier, BaggingClassifier, GradientBoostingClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "# Performance metrics\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "31uqxn9qnWq5"
   },
   "source": [
    "## Download the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3RwDC_DMnfKM"
   },
   "outputs": [],
   "source": [
    "DOWNLOAD_URL = \"https://github.com/fatimaezzahra-creator/Projet-ML/raw/refs/heads/main/datasets/adult.tgz\"\n",
    "DATASET_PATH = \"datasets\"\n",
    "\n",
    "def fetch_data(data_url, data_path):\n",
    "    if not os.path.isdir(data_path):\n",
    "        os.makedirs(data_path)\n",
    "    tgz_path = os.path.join(data_path, \"adult.tgz\")\n",
    "    urllib.request.urlretrieve(data_url, tgz_path)\n",
    "    tgz_file = tarfile.open(tgz_path)\n",
    "    tgz_file.extractall(path=data_path)\n",
    "    tgz_file.close()    \n",
    "\n",
    "def load_data():\n",
    "    csv_path = os.path.join(DATASET_PATH, \"adult.data\")\n",
    "    return pd.read_csv(csv_path, skipinitialspace=True)\n",
    "\n",
    "fetch_data(DOWNLOAD_URL, DATASET_PATH)\n",
    "data = load_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset Exploratory Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analysis of Form"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize Missing Data\n",
    "sns.heatmap(data.isna(), cbar=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that the graph is all dark, which means there is no missing values in the data ."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analysis of Content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Distribution of the Target class\n",
    "target_name = \"class\"\n",
    "data[target_name].value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Distribution of Numerical Features\n",
    "for col in data.select_dtypes(\"int64\"):\n",
    "    sns.displot(data[col])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Distribution of Categorical Attributes\n",
    "for col in data.select_dtypes(\"object\"):\n",
    "    sns.displot(data=data, x=col)\n",
    "    plt.title(f\" '{col}'\", fontsize=16)\n",
    "    plt.xlabel(col, fontsize=12)\n",
    "    plt.ylabel(\"Nombre d'observations\", fontsize=12)\n",
    "    plt.xticks(rotation=90)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a copy of the data\n",
    "df = data.copy()\n",
    "\n",
    "# Creating subsets based on the target variable\n",
    "class_0 = df[df[target_name] == \"<=50K\"]\n",
    "class_1 = df[df[target_name] == \">50K\"]\n",
    "combined_df = (pd.concat([class_0, class_1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#relation target-age\n",
    "sns.histplot(\n",
    "  data=combined_df ,\n",
    "  x=\"age\",\n",
    "  hue=\"class\",\n",
    "  stat=\"density\",\n",
    "  common_norm=False,\n",
    "  palette=\"muted\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#relation target-education_num\n",
    "sns.histplot(\n",
    "  data=combined_df ,\n",
    "  x=\"education-num\",\n",
    "  hue=\"class\",\n",
    "  stat=\"density\",\n",
    "  common_norm=False,\n",
    "  palette=\"muted\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ralation target-education\n",
    "sns.histplot(\n",
    "  data=combined_df ,\n",
    "  x=\"education\",\n",
    "  hue=\"class\",\n",
    "  stat=\"density\",\n",
    "  common_norm=False,\n",
    "  palette=\"muted\");\n",
    "plt.xticks(rotation=90)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The features education (categorical) and education-num (numerical) may convey similar information, as they both represent the education level of an individual."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FIX ME: add comment explaining what does the line below do\n",
    "education_mapping = data.groupby(\"education\")[\"education-num\"].unique()\n",
    "\n",
    "# Afficher le mapping pour vérifier la correspondance\n",
    "for edu, edu_num in education_mapping.items():\n",
    "    print(f\"Education: {edu}, Education_Num: {edu_num}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The output of this mapping shows that each education category corresponds to a single unique value of education-num in an ordinal way. That is, 1 is equivalent to the lowest level of education (Preschool), while 16 is the highest (Doctorate). This confirms that the two features are effectively encoding the same information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#relation target-workclass\n",
    "sns.histplot(\n",
    "  data=combined_df ,\n",
    "  x=\"workclass\",\n",
    "  hue=\"class\",\n",
    "  stat=\"density\",\n",
    "  common_norm=False,\n",
    "  palette=\"muted\");\n",
    "plt.xticks(rotation=90)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#relation target-sex\n",
    "sns.histplot(\n",
    "  data=combined_df ,\n",
    "  x=\"sex\",\n",
    "  hue=\"class\",\n",
    "  stat=\"density\",\n",
    "  common_norm=False,\n",
    "  palette=\"muted\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#relation target-marital status\n",
    "sns.histplot(\n",
    "  data=combined_df ,\n",
    "  x=\"marital-status\",\n",
    "  hue=\"class\",\n",
    "  stat=\"density\",\n",
    "  common_norm=False,\n",
    "  palette=\"muted\");\n",
    "plt.xticks(rotation=90)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#relation target-relationship\n",
    "sns.histplot(\n",
    "  data=combined_df ,\n",
    "  x=\"relationship\",\n",
    "  hue=\"class\",\n",
    "  stat=\"density\",\n",
    "  common_norm=False,\n",
    "  palette=\"muted\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The features relationship and marital-status  might convey similar information because a person's relationship type often depends on their marital status.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FIX ME: add comment explaining what does the line below do\n",
    "education_mapping = data.groupby(\"marital-status\")[\"relationship\"].unique()\n",
    "\n",
    "# Afficher le mapping pour vérifier la correspondance\n",
    "for mrs, rshp in education_mapping.items():\n",
    "    print(f\"marital-status: {mrs}, relationship: {rshp}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The output reveals that for each value of marital-status, there are multiple possible values for relationship.\n",
    "This variability indicates that a person's relationship cannot be uniquely determined based on their marital-status."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#relation taget-fnlwgt\n",
    "sns.histplot(\n",
    "  data=combined_df ,\n",
    "  x=\"fnlwgt\",\n",
    "  hue=\"class\",\n",
    "  stat=\"density\",\n",
    "  common_norm=False,\n",
    "  palette=\"muted\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# relation target-race\n",
    "sns.histplot(\n",
    "  data=combined_df ,\n",
    "  x=\"race\",\n",
    "  hue=\"class\",\n",
    "  stat=\"density\",\n",
    "  common_norm=False,\n",
    "  palette=\"muted\");\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#relation target-native country\n",
    "sns.histplot(\n",
    "  data=combined_df ,\n",
    "  x=\"native-country\",\n",
    "  hue=\"class\",\n",
    "  stat=\"density\",\n",
    "  common_norm=False,\n",
    "  palette=\"muted\");\n",
    "plt.xticks(rotation=90)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The native-country  and race columns in the dataset contains many unique values, some of which have very low frequencies. Keeping all these rare categories can negatively impact the machine learning model due to:\n",
    "\n",
    "Overfitting: The model may place undue importance on rare categories, learning patterns that don't generalize well to new data.\n",
    "Increased Complexity: High cardinality increases the dimensionality during encoding (e.g., in one-hot encoding), which can slow down training and complicate the model unnecessarily.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#relation target-occupation\n",
    "sns.histplot(\n",
    "  data=combined_df ,\n",
    "  x=\"occupation\",\n",
    "  hue=\"class\",\n",
    "  stat=\"density\",\n",
    "  common_norm=False,\n",
    "  palette=\"muted\");\n",
    "plt.xticks(rotation=90)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#rlation target-capital gain\n",
    "sns.histplot(\n",
    "  data=combined_df ,\n",
    "  x=\"capital-gain\",\n",
    "  hue=\"class\",\n",
    "  stat=\"density\",\n",
    "  common_norm=False,\n",
    "  palette=\"muted\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ralation target-capitalloss\n",
    "sns.histplot(\n",
    "  data=combined_df ,\n",
    "  x=\"capital-loss\",\n",
    "  hue=\"class\",\n",
    "  stat=\"density\",\n",
    "  common_norm=False,\n",
    "  palette=\"muted\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The combination of capital-gain and capital-loss into a single derived feature could have a stronger correlation with the target variable (class) than either capital-gain or capital-loss individually, potentially improving the predictive power of the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Capital Features Combination\n",
    "dff = df.copy()\n",
    "dff[\"capital-net\"] = (dff[\"capital-gain\"] - dff[\"capital-loss\"])\n",
    "dff[\"ratio\"] = (dff[\"capital-gain\"]/(dff[\"capital-loss\"]+0.00000001))\n",
    "dff[\"capital-weighted\"] = (dff[\"capital-gain\"]*0.223329 + dff[\"capital-loss\"]*0.150526)\n",
    "\n",
    "# Encodage LabelEncoder pour chaque colonne catégorique\n",
    "label_encoders = {}\n",
    "for column in dff.select_dtypes(include=['object']).columns:\n",
    "    encoder = LabelEncoder()\n",
    "    dff[column] = encoder.fit_transform(dff[column])\n",
    "    label_encoders[column] = encoder  # Stocker l'encodeur pour chaque colonne (optionnel, utile pour l'inverse_transform)\n",
    "\n",
    "# Calcul de la matrice de corrélation\n",
    "corr_matrix = dff.corr()\n",
    "corr_matrix[target_name].sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**capital-net: the net difference between gains and losses**\n",
    "\n",
    "Correlation: 0.214, lower than capital-gain. Relevance: While intuitive (netting gains and losses), this feature does not add much value compared to capital-gain alone. Consider dropping it unless it improves model performance.\n",
    "\n",
    "**ratio: relative proportion of gains to losses**\n",
    "\n",
    "Correlation: 0.223, identical to capital-gain. Relevance: This feature does not improve upon capital-gain’s correlation. Its usefulness might depend on the model's capacity to interpret non-linear relationships, but it seems redundant for linear models.\n",
    "\n",
    "**capital-weighted: weighted sum of the two based on their importance**\n",
    "\n",
    "Correlation: 0.229, slightly higher than capital-gain (0.223). This feature combines the effects of both gains and losses, weighted by their individual correlations with class. It shows a slight improvement, suggesting it may capture some additional nuanced information. This feature is pertinent to keep for modeling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#relation target- hours per week\n",
    "sns.histplot(\n",
    "  data=combined_df ,\n",
    "  x=\"hours-per-week\",\n",
    "  hue=\"class\",\n",
    "  stat=\"density\",\n",
    "  common_norm=False,\n",
    "  palette=\"bright\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Synthesis**\n",
    "\n",
    "1. Retain `education-num` (numerical feature) and remove education to avoid redundancy and simplify the dataset.\n",
    "2. Retain both features `relationship` and `marital-status` as they capture different aspects of an individual's social situation.\n",
    "3. Focus on the most impactful features:\n",
    "`education-num`, `age`, `hours-per-week`, `capital-weighted`, and categorical variables such as `relationship` and `marital-status`.\n",
    "4. The feature `fnlwgt` adds minimal value to the predictive power of the model.\n",
    "5. To reduce noise, we can group all rare categories (those with a frequency below a certain threshold, e.g., 500 occurrences) into a single category called `\"Other\"`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Pre-Processing\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Cleaning Process"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Removing Low-Impact Features** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine capital features in capital_weighted\n",
    "df[\"capital-weighted\"] = df[\"capital-gain\"] * 0.223329 + df[\"capital-loss\"] * 0.150526\n",
    "\n",
    "# Delete the redundant or irrelevant columns\n",
    "df.drop([\"education\", \"fnlwgt\", \"capital-gain\", \"capital-loss\"], axis=1, inplace=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Grouping Rare Categories into 'Other' to Simplify Data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count the frequency of each category \n",
    "native_country_counts = df['native-country'].value_counts()\n",
    "race_counts = df['race'].value_counts()\n",
    "\n",
    "# Identify categories to keep \n",
    "to_keep = native_country_counts[native_country_counts >= 500].index\n",
    "to_keep_race = race_counts[race_counts >= 500].index\n",
    "\n",
    "# Replace rare categories with \"Other\"\n",
    "df['native-country'] = df['native-country'].apply(lambda x: x if x in to_keep else 'Other')\n",
    "df['race'] = df['race'].apply(lambda x: x if x in to_keep_race else 'Other')\n",
    "\n",
    "# Verify the updated frequencies\n",
    "print(df['native-country'].value_counts())\n",
    "print(df['race'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Encoding and Scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transformation of Text and Categorical Data\n",
    "numerical_features = df.select_dtypes(include=np.number).columns.tolist()\n",
    "categorical_features = df.select_dtypes(include=['object']).columns.tolist()\n",
    "categorical_features.remove(target_name)\n",
    "\n",
    "preprocessor = ColumnTransformer([\n",
    "    (\"categorical\", OneHotEncoder(handle_unknown=\"ignore\"), categorical_features),\n",
    "    (\"numerical\", StandardScaler(), numerical_features)\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train/Test Split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We saw earlier that the distribution of the target class is NOT balanced, so to create our train and test sets we can use a StratifiedShuffleSplit that will not only shuffle the instances but also preserve the proportions in the original dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "split = StratifiedShuffleSplit(n_splits=1, test_size=0.2, random_state=42)\n",
    "\n",
    "for train_indexes, test_indexes in split.split(df, df[target_name]):\n",
    "    train_set = df.iloc[train_indexes]\n",
    "    test_set = df.iloc[test_indexes]\n",
    "\n",
    "print(\"Proportions in the original dataset:\", df[target_name].value_counts(normalize=True))\n",
    "print(\"Proportions in the train set:\", train_set[target_name].value_counts(normalize=True))\n",
    "print(\"Proportions in the test set:\", test_set[target_name].value_counts(normalize=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Separate target from the features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = train_set.drop(target_name, axis=1)\n",
    "target = train_set[target_name].copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Selection\n",
    "In this section, we will train 5 different models, evaluate them and compare to find the best one. They are:\n",
    "* A LogisticRegression;\n",
    "* An SGDClassifier;\n",
    "* A RandomForestClassifier;\n",
    "* A GradientBoostingClassifier;\n",
    "* A KNeighboursClassifier;\n",
    "\n",
    "First let's build each pipeline, with our previously defined preprocessor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LR_clf = LogisticRegression(solver='liblinear', random_state=42)\n",
    "SGD_clf = SGDClassifier(loss='hinge', random_state=42)\n",
    "RF_clf = RandomForestClassifier(random_state=42)\n",
    "GB_clf = GradientBoostingClassifier(random_state=42)\n",
    "KNN_clf = KNeighborsClassifier()\n",
    "\n",
    "LR_pipeline = Pipeline([\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('classifier', LR_clf)\n",
    "])\n",
    "SGD_pipeline = Pipeline([\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('classifier', SGD_clf)\n",
    "])\n",
    "RF_pipeline = Pipeline([\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('classifier', RF_clf)\n",
    "])\n",
    "GB_pipeline = Pipeline([\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('classifier', GB_clf)\n",
    "])\n",
    "KNN_pipeline = Pipeline([\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('classifier', KNN_clf)\n",
    "])\n",
    "\n",
    "models = {\n",
    "    'Logistic': LR_pipeline,\n",
    "    'SGD': SGD_pipeline,\n",
    "    'RandomForet': RF_pipeline,\n",
    "    'GradientBoosting': GB_pipeline,\n",
    "    'KNeighbours': KNN_pipeline \n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can define the parameter grid for each model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LR_param_grid = {\n",
    "    'classifier__penalty': ['l1','l2'],\n",
    "    'classifier__C': [0.01, 0.1, 1],\n",
    "    'classifier__max_iter' : [100, 500, 1000]\n",
    "}\n",
    "\n",
    "SGD_param_grid = {\n",
    "    'classifier__learning_rate': ['constant', 'invscaling'],\n",
    "    'classifier__eta0': [0.01, 0.1, 1],\n",
    "    'classifier__penalty': ['l2', 'l1'],\n",
    "    'classifier__alpha': [0.001, 0.01, 0.1],\n",
    "    'classifier__max_iter': [100, 500, 1000]\n",
    "}\n",
    "\n",
    "RF_param_grid = {\n",
    "    'classifier__n_estimators': [10, 50, 100],\n",
    "    'classifier__max_depth': [10, 50, 100]\n",
    "}\n",
    "\n",
    "GB_param_grid = {\n",
    "    'classifier__n_estimators': [100, 200, 300],\n",
    "    'classifier__learning_rate': [0.01, 0.05, 0.1, 0.2],\n",
    "    'classifier__max_depth': [3, 4, 5, 6],\n",
    "    'classifier__subsample': [0.7, 0.8, 0.9, 1.0]\n",
    "}\n",
    "\n",
    "KNN_param_grid = {\n",
    "    'classifier__n_neighbors': [3, 5, 7, 9, 11, 15],\n",
    "    'classifier__weights': ['uniform', 'distance'],\n",
    "    'classifier__algorithm': ['auto', 'ball_tree', 'kd_tree', 'brute'],\n",
    "    'classifier__leaf_size': [10, 20, 30, 40, 50],\n",
    "    'classifier__p': [1, 2] \n",
    "}\n",
    "\n",
    "param_grid = {\n",
    "    'Logistic': LR_param_grid,\n",
    "    'SGD': SGD_param_grid,\n",
    "    'RandomForet': RF_param_grid,\n",
    "    'GradientBoosting': GB_param_grid,\n",
    "    'KNeighbours': KNN_param_grid \n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we perform a GridSearchCV. Since the parameter grid are already pretty extensive, we will use only 3 folds."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for name, model in models.items():\n",
    "    print(f\"For the {name} model:\")\n",
    "    grid_search = GridSearchCV(\n",
    "        estimator=model,\n",
    "        param_grid=param_grid[name],\n",
    "        cv=3,                   # Validação cruzada 5-fold\n",
    "        scoring='accuracy',     # Métrica de avaliação\n",
    "        n_jobs=-1,              # Uso de todos os núcleos disponíveis\n",
    "    )\n",
    "    grid_search.fit(train_data, target)\n",
    "    print(\"    Best Hyperparams:\", grid_search.best_params_)\n",
    "    print(\"    Best Accuracy:\", grid_search.best_score_)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
